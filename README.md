# Tutorials for Physics-Informed Neural Networks (PINNs)

This repository provides step-by-step guides to Physics-informed neural networks (PINNs).

### Part 1: Data-driven machine learning methods: strengths and limits

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1na1yVhBF9MYPntbr6bfGd6qwWKl-uJGS?usp=sharing)

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nguyenkhoa0209/pinns_tutorial/main?labpath=part1_data_driven_ml.ipynb)

### Part 2: PINNs and their scope of use

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EEDH099GalrgqNbEaDgPm-OCHULBQ3HT?usp=sharing)

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nguyenkhoa0209/pinns_tutorial/main?labpath=part2_pinns_scope_of_use.ipynb)

### Part 3: Strategies to improve PINNs performance _(available soon)_

### Part 4: Integrate the geometries into PINNs _(available soon)_

### Acknowledgement
This work is funded by Michelin and CEA through the Industrial Data Analytics and Machine Learning chair of ENS Paris-Saclay

### References
Below is the list of references used in this repository.

[1] Raissi, M., Perdikaris, P. and Karniadakis, G.E., 2019. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics, 378, pp.686-707. [link to paper](https://www.sciencedirect.com/science/article/pii/S0021999118307125?casa_token=6eq_4Fcj6HsAAAAA:i_A9-C4tqlPBFV-9qT6uyIM6rJ-s1KTs9lRnvWxTU_zBnz-_Z8P-WdnkRE9w2awrQ0IFDTZRlzgJ)

[2] Lu, L., Meng, X., Mao, Z. and Karniadakis, G.E., 2021. DeepXDE: A deep learning library for solving differential equations. SIAM review, 63(1), pp.208-228. [link to paper](https://epubs.siam.org/doi/pdf/10.1137/19M1274067)

[3] McClenny, L.D. and Braga-Neto, U.M., 2023. Self-adaptive physics-informed neural networks. Journal of Computational Physics, 474, p.111722. [link o paper](https://www.sciencedirect.com/science/article/pii/S0021999122007859?casa_token=4cW6gLX5up0AAAAA:URjiW_ultgDq5NDXkBn0ReYd4kCj7gNYZIxnEsrx9c4Zp98nCUso1CnNIw7K-vDsPFG-6xCm4-GZ)

[4] Wang, S., Yu, X. and Perdikaris, P., 2022. When and why PINNs fail to train: A neural tangent kernel perspective. Journal of Computational Physics, 449, p.110768. [link to paper](https://www.sciencedirect.com/science/article/pii/S002199912100663X?casa_token=QSieq2q8ZWwAAAAA:qbG-YIp7ZNYYWMRK2oH47cUts2FCf0WoGGPI5-WYO8TVGofY86RABSVLpxEdsZw1u_JLd2_6oW4S)

[5] Wang, S., Teng, Y. and Perdikaris, P., 2021. Understanding and mitigating gradient flow pathologies in physics-informed neural networks. SIAM Journal on Scientific Computing, 43(5), pp.A3055-A3081. [link to paper](https://epubs.siam.org/doi/pdf/10.1137/20M1318043)

[6] Jagtap, A.D., Kawaguchi, K. and Em Karniadakis, G., 2020. Locally adaptive activation functions with slope recovery for deep and physics-informed neural networks. Proceedings of the Royal Society A, 476(2239), p.20200334. [link to paper](https://royalsocietypublishing.org/doi/10.1098/rspa.2020.0334)

[7] Jagtap, A.D., Shin, Y., Kawaguchi, K. and Karniadakis, G.E., 2022. Deep Kronecker neural networks: A general framework for neural networks with adaptive activation functions. Neurocomputing, 468, pp.165-180. [link to paper](https://www.sciencedirect.com/science/article/pii/S0925231221015162?casa_token=7Ys30SGl_Q0AAAAA:PmCCKsuiu4tpIdD90fpEP5X7LyMuAn80p74OXF7O2SUZ4f8dXM4Df9Y7YqOfDkEsk_fbGSmn7vlF)

[8] Nguyen, T.N.K., Dairay, T., Meunier, R., Millet, C. and Mougeot, M., 2023, June. Fixed-Budget Online Adaptive Learning for Physics-Informed Neural Networks. Towards Parameterized Problem Inference. In International Conference on Computational Science (pp. 453-468). Cham: Springer Nature Switzerland. [link to paper](https://link.springer.com/chapter/10.1007/978-3-031-36027-5_36)

[9] Wu, C., Zhu, M., Tan, Q., Kartha, Y. and Lu, L., 2023. A comprehensive study of non-adaptive and residual-based adaptive sampling for physics-informed neural networks. Computer Methods in Applied Mechanics and Engineering, 403, p.115671. [link to paper](https://www.sciencedirect.com/science/article/pii/S0045782522006260?casa_token=iZGUC2J08ToAAAAA:NCEJO60azaLuZDTZaUgDvcYG8x8B_TS2sOYtcNnh9dt7kf6DD1IjXsJVaq8HvI6DZEvUENMXSbf7)

[10] Daw, A., Bu, J., Wang, S., Perdikaris, P. and Karpatne, A., 2022. Rethinking the importance of sampling in physics-informed neural networks. arXiv preprint arXiv:2207.02338. [link to paper](https://www.researchgate.net/profile/Jie-Bu-2/publication/361808020_Rethinking_the_Importance_of_Sampling_in_Physics-informed_Neural_Networks/links/62cfc74e7156f534a68087d5/Rethinking-the-Importance-of-Sampling-in-Physics-informed-Neural-Networks.pdf)

[11] Wang, S., Sankaran, S. and Perdikaris, P., 2022. Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404. [link to paper](https://arxiv.org/pdf/2203.07404.pdf)

[12] Nguyen, T.N.K., Dairay, T., Meunier, R. and Mougeot, M., 2022. Physics-informed neural networks for non-Newtonian fluid thermo-mechanical problems: An application to rubber calendering process. Engineering Applications of Artificial Intelligence, 114, p.105176. [link to paper](https://www.sciencedirect.com/science/article/pii/S0952197622002810?casa_token=H3SHY14AUSIAAAAA:dWPcruLe3qsgCtjmdloXHV99mZCCqCsnWRdpSG3_KfZUmUZ-cMdGaKARR2JbNEXPah9gcGZtP2bS)